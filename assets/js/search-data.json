{
  
    
        "post0": {
            "title": "Develop Android app to park a camper level",
            "content": "Develop Android app to park a camper level . . In the blog Rotationssensor MPU-6050 mit WebGL am Raspberry Pi visualisieren . Der Raspberry Pi ist zu vielem in der Lage, so können einfach Rotations- und Beschleunigugnswerte mittels eines Sensors, wie dem MPU-6050, ausgelesen werden. Das Ergebnis sind jedoch einfache Zahlen, worunter man sich im Normalfall nicht all zu viel vorstellen wird. Jedoch ist es sehr einfach diese Zahlen zu visualisieren. Dies geht in modernen Browsern ganz einfach mittels WebGL, womit man 2D und 3D Objekte im Browser rendern kann. . Sensor MPU 6050 VNC: Remote access a Raspberry Pi . Setting up a VNC connection from phone to the raspi follow the instructions given at . https://magpi.raspberrypi.org/articles/vnc-raspberry-pi . Setting up a Raspberry Pi as a Wireless Access Point . Setting up the raspi as a wireless access point so that you can use VNC on a camping ground follow instructions given at https://www.raspberrypi.org/documentation/configuration/wireless/access-point.md This documentation assumes that we are using the standard 192.168.x.x IP addresses for our wireless network, so we will assign the server the IP address 192.168.4.1. . Note: Change default in sudo nano /etc/hostapd/hostapd.conf to something meaningful to you . ssid=NameOfNetwork # change this hw_mode=g channel=7 wmm_enabled=0 macaddr_acl=0 auth_algs=1 ignore_broadcast_ssid=0 wpa=2 wpa_passphrase=AardvarkBadgerHedgehog # change this . Measuring Rotation and acceleration with the Raspberry Pi . Follow instructions at MPU6050 (Accelerometer+Gyroscope) Interfacing with Raspberry Pi https://www.electronicwings.com/raspberry-pi/mpu6050-accelerometergyroscope-interfacing-with-raspberry-pi . Calculate pitch and roll . from MPU6050_9Axis_MotionApps41.h . uint8_t MPU6050::dmpGetYawPitchRoll(float data, Quaternion *q, VectorFloat *gravity) { // yaw: (about Z axis) data[0] = atan2(2q -&gt; xq -&gt; y - 2q -&gt; wq -&gt; z, 2q -&gt; wq -&gt; w + 2q -&gt; xq -&gt; x - 1); // pitch: (nose up/down, about Y axis) data[1] = atan(gravity -&gt; x / sqrt(gravity -&gt; ygravity -&gt; y + gravity -&gt; zgravity -&gt; z)); // roll: (tilt left/right, about X axis) data[2] = atan(gravity -&gt; y / sqrt(gravity -&gt; xgravity -&gt; x + gravity -&gt; z*gravity -&gt; z)); return 0; . The following output . Gyroscope ——– gyroscope_xout: -260 scaled: -2 gyroscope_yout: -154 scaled: -2 gyroscope_zout: 78 scaled: 0 . Accelerometer . acceleration_xout: -1048 scaled: -0.06396484375 acceleration_yout: -676 scaled: -0.041259765625 acceleration_zout: 16644 scaled: 1.01586914062 X Rotation: -2.32121150537 Y Rotation: 3.59994842011 . is created by [Measuring Rotation and acceleration with the Raspberry Pi](http://www.raspberrypirobotics.com/measuring-rotation-and-acceleration-with-the-raspberry-pi/) python #!/usr/bin/python import smbus import math # Register power_mgmt_1 = 0x6b power_mgmt_2 = 0x6c def read_byte(reg): return bus.read_byte_data(address, reg) def read_word(reg): h = bus.read_byte_data(address, reg) l = bus.read_byte_data(address, reg+1) value = (h &lt;&lt; 8) + l return value def read_word_2c(reg): val = read_word(reg) if (val &gt;= 0x8000): return -((65535 - val) + 1) else: return val def dist(a,b): return math.sqrt((a*a)+(b*b)) def get_y_rotation(x,y,z): radians = math.atan2(x, dist(y,z)) return -math.degrees(radians) def get_x_rotation(x,y,z): radians = math.atan2(y, dist(x,z)) return math.degrees(radians) bus = smbus.SMBus(1) # bus = smbus.SMBus(0) fuer Revision 1 address = 0x68 # via i2cdetect # Aktivieren, um das Modul ansprechen zu koennen bus.write_byte_data(address, power_mgmt_1, 0) print &quot;Gyroscope Sensor&quot; print &quot;--&quot; gyroscope_xout = read_word_2c(0x43) gyroscope_yout = read_word_2c(0x45) gyroscope_zout = read_word_2c(0x47) print &quot;gyroscope_xout: &quot;, (&quot;%5d&quot; % gyroscope_xout), &quot; scaled: &quot;, (gyroscope_xout / 131) print &quot;gyroscope_yout: &quot;, (&quot;%5d&quot; % gyroscope_yout), &quot; scaled: &quot;, (gyroscope_yout / 131) print &quot;gyroscope_zout: &quot;, (&quot;%5d&quot; % gyroscope_zout), &quot; scaled: &quot;, (gyroscope_zout / 131) print print &quot;Accelerometer Sensor&quot; print &quot;&quot; acceleration_xout = read_word_2c(0x3b) acceleration_yout = read_word_2c(0x3d) acceleration_zout = read_word_2c(0x3f) acceleration_xout_scaled = acceleration_xout / 16384.0 acceleration_yout_scaled = acceleration_yout / 16384.0 acceleration_zout_scaled = acceleration_zout / 16384.0 print &quot;acceleration_xout: &quot;, (&quot;%6d&quot; % acceleration_xout), &quot; scaled: &quot;, acceleration_xout_scaled print &quot;acceleration_yout: &quot;, (&quot;%6d&quot; % acceleration_yout), &quot; scaled: &quot;, acceleration_yout_scaled print &quot;acceleration_zout: &quot;, (&quot;%6d&quot; % acceleration_zout), &quot; scaled: &quot;, acceleration_zout_scaled print &quot;X Rotation: &quot; , get_x_rotation(acceleration_xout_scaled, acceleration_yout_scaled, acceleration_zout_scaled) print &quot;Y Rotation: &quot; , get_y_rotation(acceleration_xout_scaled, acceleration_yout_scaled, acceleration_zout_scaled) . Sending data to an HTTP server - get and post methods . Sending data to an HTTP server - get and post methods . MQTT . Eclipse Mosquitto™ An open source MQTT broker Mosquitto is highly portable and available for a wide range of platforms. For Raspberry Pi Mosquitto is available through the main repository. . Introduction to IoT: Build an MQTT Server Using Raspberry Pi . https://appcodelabs.com/introduction-to-iot-build-an-mqtt-server-using-raspberry-pi .",
            "url": "https://uwesterr.github.io/MlFastAiBlog/raspi/mpu6050/android/2020/03/11/MPU6050-Raspi-Arduino.html",
            "relUrl": "/raspi/mpu6050/android/2020/03/11/MPU6050-Raspi-Arduino.html",
            "date": " • Mar 11, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Train donkeycar with GPU support in Colab",
            "content": ". Credit . . Note: This notebook is based on https://colab.research.google.com/github/robocarstore/donkey-car-training-on-google-colab/blob/master/Donkey_Car_Training_using_Google_Colab.ipynb . Get necessary libraries . #collapse-hide %tensorflow_version 1.13.1 import tensorflow from google.colab import drive from google.colab import files from IPython.display import Image import glob import shutil . . `%tensorflow_version` only switches the major version: 1.x or 2.x. You set: `1.13.1`. This will be interpreted as: `1.x`. TensorFlow 1.x selected. . Step 1: Create environment . To train a neural network for the donkeycar we need a few components . install donkeycar | upload data via direct upload | mount Google drive | . | . . Note: Donkeycar at the time of writing in March 2020 uses Tensorflow 1.13, therefore version 1.xx is installed . #collapse-show print(tensorflow.__version__) . . 1.15.2 . Git Clone the donkeycar repository . Get the latest donkeycar version from GitHub . Note: The default branch is &quot;dev&quot;, however, the documentation is for the master branch. . !git clone https://github.com/autorope/donkeycar.git %cd /content/donkeycar !git checkout master . Cloning into &#39;donkeycar&#39;... remote: Enumerating objects: 12972, done. remote: Total 12972 (delta 0), reused 0 (delta 0), pack-reused 12972 Receiving objects: 100% (12972/12972), 67.74 MiB | 12.56 MiB/s, done. Resolving deltas: 100% (8193/8193), done. /content/donkeycar Branch &#39;master&#39; set up to track remote branch &#39;master&#39; from &#39;origin&#39;. Switched to a new branch &#39;master&#39; . Install donkey car . Different to the description at http://docs.donkeycar.com/guide/host_pc/setup_ubuntu/ we create no anaconda environment since the script is supposed to run on Colab which will delete the instance anyway once you disconnect the notebook. . !pip3 install -e .[pc] . Obtaining file:///content/donkeycar Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.2) (1.18.4) Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.2) (7.0.0) Requirement already satisfied: docopt in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.2) (0.6.2) Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.2) (4.5.3) Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.2) (2.23.0) Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.2) (2.10.0) Requirement already satisfied: moviepy in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.2) (0.2.3.5) Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.2) (1.0.3) Requirement already satisfied: PrettyTable in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.2) (0.7.2) Collecting paho-mqtt Downloading https://files.pythonhosted.org/packages/59/11/1dd5c70f0f27a88a3a05772cd95f6087ac479fac66d9c7752ee5e16ddbbc/paho-mqtt-1.5.0.tar.gz (99kB) |████████████████████████████████| 102kB 2.0MB/s Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.2) (3.2.1) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;donkeycar==3.1.2) (2.9) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;donkeycar==3.1.2) (1.24.3) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;donkeycar==3.1.2) (2020.4.5.1) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;donkeycar==3.1.2) (3.0.4) Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py-&gt;donkeycar==3.1.2) (1.12.0) Requirement already satisfied: imageio&lt;3.0,&gt;=2.1.2 in /usr/local/lib/python3.6/dist-packages (from moviepy-&gt;donkeycar==3.1.2) (2.4.1) Requirement already satisfied: tqdm&lt;5.0,&gt;=4.11.2 in /usr/local/lib/python3.6/dist-packages (from moviepy-&gt;donkeycar==3.1.2) (4.41.1) Requirement already satisfied: decorator&lt;5.0,&gt;=4.0.2 in /usr/local/lib/python3.6/dist-packages (from moviepy-&gt;donkeycar==3.1.2) (4.4.2) Requirement already satisfied: python-dateutil&gt;=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas-&gt;donkeycar==3.1.2) (2.8.1) Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas-&gt;donkeycar==3.1.2) (2018.9) Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib-&gt;donkeycar==3.1.2) (1.2.0) Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib-&gt;donkeycar==3.1.2) (2.4.7) Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib-&gt;donkeycar==3.1.2) (0.10.0) Building wheels for collected packages: paho-mqtt Building wheel for paho-mqtt (setup.py) ... done Created wheel for paho-mqtt: filename=paho_mqtt-1.5.0-cp36-none-any.whl size=61416 sha256=b22abeeacae2354c02444fdf25112a201d4044fb0ee784d51ea0d9b2c1b14e81 Stored in directory: /root/.cache/pip/wheels/02/94/6c/8474137cb7a5a3e001d70a22c8ff919caee69435376bccce79 Successfully built paho-mqtt Installing collected packages: paho-mqtt, donkeycar Running setup.py develop for donkeycar Successfully installed donkeycar paho-mqtt-1.5.0 . Create Project . In this step the following actions take place . create necessary folders (models, data, logs) | copying necessary files into folders (manage.py, myconfig.py etc.) | . !donkey createcar --path /content/mycar . using donkey v3.1.2 ... Creating car folder: /content/mycar making dir /content/mycar Creating data &amp; model folders. making dir /content/mycar/models making dir /content/mycar/data making dir /content/mycar/logs Copying car application template: complete Copying car config defaults. Adjust these before starting your car. Copying train script. Adjust these before starting your car. Copying my car config overrides Donkey setup complete. . Step 2: Supply Data . In order to train the neural network we need to supply trainings data which are recorded on the raspi during driving the donkeycar on the track . Step 2 opt A: Supply own data . If you have own data proceed here, if you want to use data which were made available via GitHub please continue to (link only works in blog not in Colab) section Supply GitHub hosted data . Zip data on raspi . Copy the following code and run on raspi . Note: Copying of the data is much faster if the data is zipped to one file. . cd ~/mycar/data # either compress just one folder tar -czf tub_xx_yyyy_mm_dd.tar.gz tub_xx_yyyy_mm_dd # or all folders starting with &quot;tub&quot; tar -czf trainingsData2020_03-01.tar.gz tub* . This will create a tub_xx_yyyy_mm_dd.tar.gz file under ~/mycar/data . Copy the zipped tub to your local PC . Run this on your local pc if you are using linux/mac . sftp pi@raspberry.local cd ~/mycar/data get tub_xx_yyyy_mm_dd.tar.gz . If you are on a windows, download sftp utility like filezilla or putty . Define your tub name here . tub_name=&quot;tubVaihingenIIICleaned200126&quot; . Upload the tub from Google Drive . First upload the tub_x_yyyy_mm_dd.tar.gz to Google Drive. We will then mount Google Drive from colab and copy the data from Drive directly. . Note: To copy data from Google Drive to Colab is faster than uploading it from local machine. When you run the cell below, you will need to click the link and generate an authorization code to for colab to access your drive. . drive.mount(&#39;/content/drive&#39;) . Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&amp;redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&amp;response_type=code&amp;scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly Enter your authorization code: ·········· Mounted at /content/drive . Suppose you upload the tub_xx_yyyy_mm_dd.tar.gz to Google Drive/mycar/tub_xx_yyyy_mm_dd.tar.gz, this is how you copy it from Google Drive to colab . %cd /content/mycar !rm -rf data !mkdir data %cd /content/mycar/data !cp /content/drive/My Drive/myCar/{tub_name}.tar.gz . . /content/mycar /content/mycar/data . And untar it to the right place . %cd /content/mycar/data !tar -xzf {tub_name}.tar.gz . /content/mycar/data . Lets look at one image to see we got valid data . %cd /content/mycar/data/tubVaihingenIIICleaned200126/ file = glob.glob(&quot;*.jpg&quot;) Image(file[100]) . /content/mycar/data/tubVaihingenIIICleaned200126 . Check quality of data . You want data which has left and right turns preferably in equal shares. A histogram is a good tool to check if this is the case. You can use a donkeycar tool for that . donkey tubhist &lt;tub_path&gt; --rec=&lt;&quot;user/angle&quot;&gt; . The histogram shows that mainly the car drove straight ahead and more left turns than right turns. It is good practice to drive a course clock wise and anti clock wise to avoid this imbalance. . %cd /content/mycar !donkey tubhist --tub data/{tub_name} --rec=&quot;user/angle&quot; file = glob.glob(&quot;tubVaihingenIIICleaned200126_hist_user_angle.png&quot;) Image(file[0]) . /content/mycar using donkey v3.1.2 ... TubGroup:tubpaths: [&#39;/content/mycar/data/tubVaihingenIIICleaned200126&#39;] joining the tubs 14234 records together. This could take 0 minutes. saving image to: tubVaihingenIIICleaned200126_hist_user_angle.png &lt;Figure size 640x480 with 1 Axes&gt; . Next step is to train your model in section Upload local files (Link only works in blog not in Colab) . Supply GitHub hosted data . If you don&#39;t have own training data you might want to use an example data set . Note: The training data is cleaned (tubclean) but whether or not you get a good working model out of it... See instructions below how to get the data into the Colab environment . The training data are hosted on GitHub . clone GitHub repo | move file to data folder | unzip file | . Step 2 opt B: Use data from RoboCarEsslingen . The first data set we use is from RoboCar Esslingen GitHub which is operated by the meetup group Esslinger Makerspace Projekt: Autonomen RoboCar bauen located in Esslingen, Germany. The data was recorded at #8.7 Quarterly Hack: DIYrobocars Build &amp; Race in Suttgart with kind support of Bosch. If you want to use data from Connected Atonomous Mobility proceed in chapter (link only works in blog not in Colab) section Use data from Connected Autonomous Mobility . %cd /content/mycar !rm -rf data !mkdir data %cd /content/mycar/data !pwd ! git clone --recursive https://github.com/RoboCarEsslingen/trainingData.git . /content/mycar /content/mycar/data /content/mycar/data Cloning into &#39;trainingData&#39;... remote: Enumerating objects: 4, done. remote: Counting objects: 100% (4/4), done. remote: Compressing objects: 100% (4/4), done. remote: Total 4 (delta 0), reused 4 (delta 0), pack-reused 0 Unpacking objects: 100% (4/4), done. . Move zip file to data folder and unzip . shutil.move(&quot;/content/mycar/data/trainingData/tubVaihingenIIICleaned200126.tar.gz&quot;, &quot;/content/mycar/data&quot;) . &#39;/content/mycar/data/tubVaihingenIIICleaned200126.tar.gz&#39; . Unzip the training data file . %cd /content/mycar/data !tar -xzf tubVaihingenIIICleaned200126.tar.gz . /content/mycar/data . Check quality of data . You want data which has left and right turns preferably in equal shares. A histogram is a good tool to check if this is the case. You can use a donkeycar tool for that . donkey tubhist &lt;tub_path&gt; --rec=&lt;&quot;user/angle&quot;&gt; . The histogram shows that mainly the car drove straight ahead and more left turns than right turns. It is good practice to drive a course clock wise and anti clock wise to avoid this imbalance. . %cd /content/mycar !donkey tubhist --tub data/{tub_name} --rec=&quot;user/angle&quot; file = glob.glob(&quot;tubVaihingenIIICleaned200126_hist_user_angle.png&quot;) Image(file[0]) . /content/mycar using donkey v3.1.2 ... TubGroup:tubpaths: [&#39;/content/mycar/data/tubVaihingenIIICleaned200126&#39;] joining the tubs 14234 records together. This could take 0 minutes. saving image to: tubVaihingenIIICleaned200126_hist_user_angle.png &lt;Figure size 640x480 with 1 Axes&gt; . Use data from Connected Autonomous Mobility . Another data set is from Connected Autonomous Mobility We clone the whole repo because I don&#39;t know how to download a single file from a GitHub repo, if you know how to this than please leave a note the comment section. . %cd /content/mycar !rm -rf data !mkdir data %cd /content/mycar/data !pwd ! git clone --recursive https://github.com/connected-autonomous-mobility/20-data . /content/mycar /content/mycar/data /content/mycar/data Cloning into &#39;20-data&#39;... remote: Enumerating objects: 19, done. remote: Counting objects: 100% (19/19), done. remote: Compressing objects: 100% (19/19), done. remote: Total 80 (delta 8), reused 0 (delta 0), pack-reused 61 Unpacking objects: 100% (80/80), done. . Move zip file to data folder and unzip . import shutil shutil.move(&quot;/content/mycar/data/20-data/20190414-BOSCH-Solaris-Course/tub_36_19-04-13.zip&quot;, &quot;/content/mycar/data&quot;) . &#39;/content/mycar/data/tub_36_19-04-13.zip&#39; . Unzip the training data file . %cd /content/mycar/data !unzip tub_36_19-04-13.zip . Lets look at one image to get an impression what the car saw. . # This is formatted as code . %cd /content/mycar/data/tub_36_19-04-13/ file = glob.glob(&quot;*.jpg&quot;) Image(file[300]) . /content/mycar/data/tub_36_19-04-13 . Check quality of data . You want data which has left and right turns preferably in equal shares. A histogram is a good tool to check if this is the case. You can use a donkeycar tool for that . donkey tubhist &lt;tub_path&gt; --rec=&lt;&quot;user/angle&quot;&gt; . The histogram shows that mainly the car drove straight ahead, left and right turns are pretty well balanced . tub_name=&quot;tub_36_19-04-13&quot; %cd /content/mycar !donkey tubhist --tub data/{tub_name} --rec=&quot;user/angle&quot; file = glob.glob(&quot;tub_36_19-04-13_hist_user_angle.png&quot;) Image(file[0]) . /content/mycar using donkey v3.1.1 ... TubGroup:tubpaths: [&#39;/content/mycar/data/tub_36_19-04-13&#39;] joining the tubs 9136 records together. This could take 0 minutes. saving image to: tub_36_19-04-13_hist_user_angle.png &lt;Figure size 640x480 with 1 Axes&gt; . Step 3: Upload local files . You can upload files from local machine as well, but probably is slower than above approach downloading files from Google Drive . # uploaded = files.upload() . Get myconfig.py . The file myconfig.py has to be the identical during training and driving, therefore it makes sense to upload the myconfig.py which you are using on the car. . Note: In myconfig.py there are parameters which control the training such as: . line parameter --type to the python manage.py train and drive commands. DEFAULT_MODEL_TYPE = &#39;linear&#39; (linear|categorical|rnn|imu|behavior|3d|localizer|latent) BATCH_SIZE = 128 how many records to use when doing one pass of gradient decent. Use a smaller number if your gpu is running out of memory. TRAIN_TEST_SPLIT = 0.8 what percent of records to use for training. the remaining used for validation. MAX_EPOCHS = 100 how many times to visit all records of your data SHOW_PLOT = True would you like to see a pop up display of final loss? VEBOSE_TRAIN = True would you like to see a progress bar with text during training? USE_EARLY_STOP = True would you like to stop the training if we see it&#39;s not improving fit? EARLY_STOP_PATIENCE = 5 how many epochs to wait before no improvement MIN_DELTA = .0005 early stop will want this much loss change before calling it improved. PRINT_MODEL_SUMMARY = True print layers and weights to stdout OPTIMIZER = None adam, sgd, rmsprop, etc.. None accepts default LEARNING_RATE = 0.001 only used when OPTIMIZER specified LEARNING_RATE_DECAY = 0.0 only used when OPTIMIZER specified SEND_BEST_MODEL_TO_PI = False change to true to automatically send best model during training CACHE_IMAGES = True keep images in memory. will speed successive epochs, but crater if not enough mem. PRUNE_CNN = False This will remove weights from your model. The primary goal is to increase performance. PRUNE_PERCENT_TARGET = 75 The desired percentage of pruning. PRUNE_PERCENT_PER_ITERATION = 20 Percentage of pruning that is perform per iteration. PRUNE_VAL_LOSS_DEGRADATION_LIMIT = 0.2 The max amount of validation loss that is permitted during pruning. PRUNE_EVAL_PERCENT_OF_DATASET = .05 percent of dataset used to perform evaluation of model. RNN or 3D SEQUENCE_LENGTH = 3 #some models use a number of images over time. This controls how many. # # Region of interest cropping # # only supported in Categorical and Linear models. ROI_CROP_TOP = 0 #the number of rows of pixels to ignore on the top of the image ROI_CROP_BOTTOM = 0 #the number of rows of pixels to ignore on the bottom of the image . %cd /content/mycar !cp /content/drive/My Drive/myCar/myconfig.py . . /content/mycar . Step 4: Train your model . There are several types of modes available: . linear | categorical | rnn | imu | behavior | 3d | localizer And you can use pre-trained models by adding a flag [--transfer=&lt;model&gt;] | . | . Step 4 opt A: Transfer training of model . . Note: You can use a pre-trained model and use transfer learning . Do not forget to set the variables in myconfig.py . FREEZE_LAYERS = True `#default False will allow all layers to be modified by training NUM_LAST_LAYERS_TO_TRAIN = 7 `#when freezing layers, how many layers from the last should be allowed to train? . Upload pre-trained model . Upload model in case you want to use a pre-trained model for transfer learning. To define which layers shall be trained and which shall be frozen set the parameters in `myconfig.py`` . Model transfer options . When copying weights during a model transfer operation, should we freeze a certain number of layers to the incoming weights and not allow them to change during training? . FREEZE_LAYERS = False #default False will allow all layers to be modified by training NUM_LAST_LAYERS_TO_TRAIN = 7 #when freezing layers, how many layers from the last should be allowed to train? . %cd /content/mycar/models !cp /content/drive/My Drive/myCar/base_linear.h5 . . /content/mycar/models . Plot the model structure . from tensorflow.keras.utils import plot_model from tensorflow.keras.models import load_model %cd /content/mycar/models model = load_model(&#39;base_linear.h5&#39;) plot_model( model, to_file=&quot;model.png&quot;, show_shapes=False, show_layer_names=True, rankdir=&quot;TB&quot;, expand_nested=False, dpi=96, ) . /content/mycar/models . Start transfer learning of pre-trained model . Use the manage.py script to start training . !python /content/mycar/manage.py train --type=linear --transfer=/content/mycar/models/base_linear.h5 --model=/content/mycar/models/mypilot.h5 . using donkey v3.1.2 ... loading config file: /content/mycar/config.py myconfig myconfig.py loading personal config over-rides from myconfig.py config loaded &#34;get_model_by_type&#34; model Type is: linear WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating: If using Keras pass *_constraint arguments to layers. training with model type &lt;class &#39;donkeycar.parts.keras.KerasLinear&#39;&gt; loading weights from model /content/mycar/models/base_linear.h5 WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version. Instructions for updating: Call initializer instance with the dtype argument instead of passing it to the constructor WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version. Instructions for updating: Call initializer instance with the dtype argument instead of passing it to the constructor WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version. Instructions for updating: Call initializer instance with the dtype argument instead of passing it to the constructor 2020-05-28 08:43:34.472116: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1 2020-05-28 08:43:34.490930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-05-28 08:43:34.491833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235 pciBusID: 0000:00:04.0 2020-05-28 08:43:34.492256: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1 2020-05-28 08:43:34.494369: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10 2020-05-28 08:43:34.496208: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10 2020-05-28 08:43:34.496556: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10 2020-05-28 08:43:34.498216: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10 2020-05-28 08:43:34.499878: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10 2020-05-28 08:43:34.504234: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7 2020-05-28 08:43:34.504378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-05-28 08:43:34.505248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-05-28 08:43:34.505902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0 2020-05-28 08:43:34.511896: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz 2020-05-28 08:43:34.512240: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ca6fc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices: 2020-05-28 08:43:34.512350: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version 2020-05-28 08:43:34.567565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-05-28 08:43:34.568474: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ca7180 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices: 2020-05-28 08:43:34.568509: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Tesla K80, Compute Capability 3.7 2020-05-28 08:43:34.568807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-05-28 08:43:34.569716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235 pciBusID: 0000:00:04.0 2020-05-28 08:43:34.569809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1 2020-05-28 08:43:34.569875: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10 2020-05-28 08:43:34.569935: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10 2020-05-28 08:43:34.569981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10 2020-05-28 08:43:34.570016: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10 2020-05-28 08:43:34.570042: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10 2020-05-28 08:43:34.570070: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7 2020-05-28 08:43:34.570211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-05-28 08:43:34.572597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-05-28 08:43:34.573392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0 2020-05-28 08:43:34.573493: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1 2020-05-28 08:43:34.575343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix: 2020-05-28 08:43:34.575386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186] 0 2020-05-28 08:43:34.575412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0: N 2020-05-28 08:43:34.575639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-05-28 08:43:34.576725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-05-28 08:43:34.577829: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0. 2020-05-28 08:43:34.577905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -&gt; physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7) Model: &#34;model&#34; __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== img_in (InputLayer) [(None, 120, 160, 3) 0 __________________________________________________________________________________________________ cropping2d (Cropping2D) (None, 120, 160, 3) 0 img_in[0][0] __________________________________________________________________________________________________ batch_normalization_v1 (BatchNo (None, 120, 160, 3) 12 cropping2d[0][0] __________________________________________________________________________________________________ conv2d_1 (Conv2D) (None, 58, 78, 24) 1824 batch_normalization_v1[0][0] __________________________________________________________________________________________________ dropout (Dropout) (None, 58, 78, 24) 0 conv2d_1[0][0] __________________________________________________________________________________________________ conv2d_2 (Conv2D) (None, 27, 37, 32) 19232 dropout[0][0] __________________________________________________________________________________________________ dropout_1 (Dropout) (None, 27, 37, 32) 0 conv2d_2[0][0] __________________________________________________________________________________________________ conv2d_3 (Conv2D) (None, 12, 17, 64) 51264 dropout_1[0][0] __________________________________________________________________________________________________ dropout_2 (Dropout) (None, 12, 17, 64) 0 conv2d_3[0][0] __________________________________________________________________________________________________ conv2d_4 (Conv2D) (None, 10, 15, 64) 36928 dropout_2[0][0] __________________________________________________________________________________________________ dropout_3 (Dropout) (None, 10, 15, 64) 0 conv2d_4[0][0] __________________________________________________________________________________________________ conv2d_5 (Conv2D) (None, 8, 13, 64) 36928 dropout_3[0][0] __________________________________________________________________________________________________ dropout_4 (Dropout) (None, 8, 13, 64) 0 conv2d_5[0][0] __________________________________________________________________________________________________ flattened (Flatten) (None, 6656) 0 dropout_4[0][0] __________________________________________________________________________________________________ dense (Dense) (None, 100) 665700 flattened[0][0] __________________________________________________________________________________________________ dropout_5 (Dropout) (None, 100) 0 dense[0][0] __________________________________________________________________________________________________ dense_1 (Dense) (None, 50) 5050 dropout_5[0][0] __________________________________________________________________________________________________ dropout_6 (Dropout) (None, 50) 0 dense_1[0][0] __________________________________________________________________________________________________ n_outputs0 (Dense) (None, 1) 51 dropout_6[0][0] __________________________________________________________________________________________________ n_outputs1 (Dense) (None, 1) 51 dropout_6[0][0] ================================================================================================== Total params: 817,040 Trainable params: 817,034 Non-trainable params: 6 __________________________________________________________________________________________________ None found 0 pickles writing json records and images in tub /content/mycar/data/tubVaihingenIIICleaned200126 /content/mycar/data/tubVaihingenIIICleaned200126 collating 14234 records ... train: 11387, val: 2847 total records: 14234 steps_per_epoch 177 Epoch 1/10 2020-05-28 08:43:38.483435: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10 2020-05-28 08:43:38.675268: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7 176/177 [============================&gt;.] - ETA: 0s - loss: 0.3700 - n_outputs0_loss: 0.2313 - n_outputs1_loss: 0.1387Epoch 1/10 44/177 [======&gt;.......................] - ETA: 7s - loss: 0.8251 - n_outputs0_loss: 0.6611 - n_outputs1_loss: 0.1640 Epoch 00001: val_loss improved from inf to 0.82507, saving model to /content/mycar/models/mypilot.h5 177/177 [==============================] - 17s 96ms/step - loss: 0.3692 - n_outputs0_loss: 0.2312 - n_outputs1_loss: 0.1380 - val_loss: 0.8251 - val_n_outputs0_loss: 0.6611 - val_n_outputs1_loss: 0.1640 Epoch 2/10 176/177 [============================&gt;.] - ETA: 0s - loss: 0.1923 - n_outputs0_loss: 0.1748 - n_outputs1_loss: 0.0175Epoch 1/10 43/177 [======&gt;.......................] - ETA: 2s - loss: 0.6432 - n_outputs0_loss: 0.6301 - n_outputs1_loss: 0.0131 Epoch 00002: val_loss improved from 0.82507 to 0.64266, saving model to /content/mycar/models/mypilot.h5 177/177 [==============================] - 10s 54ms/step - loss: 0.1925 - n_outputs0_loss: 0.1751 - n_outputs1_loss: 0.0175 - val_loss: 0.6427 - val_n_outputs0_loss: 0.6291 - val_n_outputs1_loss: 0.0136 Epoch 3/10 176/177 [============================&gt;.] - ETA: 0s - loss: 0.1748 - n_outputs0_loss: 0.1615 - n_outputs1_loss: 0.0132Epoch 1/10 41/177 [=====&gt;........................] - ETA: 2s - loss: 0.7503 - n_outputs0_loss: 0.7216 - n_outputs1_loss: 0.0287 Epoch 00003: val_loss did not improve from 0.64266 177/177 [==============================] - 9s 53ms/step - loss: 0.1749 - n_outputs0_loss: 0.1617 - n_outputs1_loss: 0.0132 - val_loss: 0.7543 - val_n_outputs0_loss: 0.7262 - val_n_outputs1_loss: 0.0281 Epoch 4/10 175/177 [============================&gt;.] - ETA: 0s - loss: 0.1643 - n_outputs0_loss: 0.1521 - n_outputs1_loss: 0.0122Epoch 1/10 42/177 [======&gt;.......................] - ETA: 2s - loss: 0.4721 - n_outputs0_loss: 0.4645 - n_outputs1_loss: 0.0076 Epoch 00004: val_loss improved from 0.64266 to 0.47162, saving model to /content/mycar/models/mypilot.h5 177/177 [==============================] - 10s 54ms/step - loss: 0.1644 - n_outputs0_loss: 0.1523 - n_outputs1_loss: 0.0122 - val_loss: 0.4716 - val_n_outputs0_loss: 0.4634 - val_n_outputs1_loss: 0.0082 Epoch 5/10 176/177 [============================&gt;.] - ETA: 0s - loss: 0.1552 - n_outputs0_loss: 0.1432 - n_outputs1_loss: 0.0120Epoch 1/10 44/177 [======&gt;.......................] - ETA: 2s - loss: 0.2336 - n_outputs0_loss: 0.2236 - n_outputs1_loss: 0.0099 Epoch 00005: val_loss improved from 0.47162 to 0.23356, saving model to /content/mycar/models/mypilot.h5 177/177 [==============================] - 10s 54ms/step - loss: 0.1551 - n_outputs0_loss: 0.1431 - n_outputs1_loss: 0.0120 - val_loss: 0.2336 - val_n_outputs0_loss: 0.2236 - val_n_outputs1_loss: 0.0099 Epoch 6/10 176/177 [============================&gt;.] - ETA: 0s - loss: 0.1483 - n_outputs0_loss: 0.1369 - n_outputs1_loss: 0.0114Epoch 1/10 42/177 [======&gt;.......................] - ETA: 2s - loss: 0.1471 - n_outputs0_loss: 0.1437 - n_outputs1_loss: 0.0035 Epoch 00006: val_loss improved from 0.23356 to 0.14596, saving model to /content/mycar/models/mypilot.h5 177/177 [==============================] - 10s 54ms/step - loss: 0.1481 - n_outputs0_loss: 0.1368 - n_outputs1_loss: 0.0114 - val_loss: 0.1460 - val_n_outputs0_loss: 0.1426 - val_n_outputs1_loss: 0.0034 Epoch 7/10 176/177 [============================&gt;.] - ETA: 0s - loss: 0.1391 - n_outputs0_loss: 0.1281 - n_outputs1_loss: 0.0110Epoch 1/10 41/177 [=====&gt;........................] - ETA: 2s - loss: 0.1403 - n_outputs0_loss: 0.1369 - n_outputs1_loss: 0.0034 Epoch 00007: val_loss improved from 0.14596 to 0.14012, saving model to /content/mycar/models/mypilot.h5 177/177 [==============================] - 10s 54ms/step - loss: 0.1390 - n_outputs0_loss: 0.1280 - n_outputs1_loss: 0.0110 - val_loss: 0.1401 - val_n_outputs0_loss: 0.1369 - val_n_outputs1_loss: 0.0033 Epoch 8/10 176/177 [============================&gt;.] - ETA: 0s - loss: 0.1363 - n_outputs0_loss: 0.1255 - n_outputs1_loss: 0.0108Epoch 1/10 44/177 [======&gt;.......................] - ETA: 2s - loss: 0.1400 - n_outputs0_loss: 0.1364 - n_outputs1_loss: 0.0037 Epoch 00008: val_loss improved from 0.14012 to 0.14003, saving model to /content/mycar/models/mypilot.h5 177/177 [==============================] - 10s 54ms/step - loss: 0.1363 - n_outputs0_loss: 0.1253 - n_outputs1_loss: 0.0110 - val_loss: 0.1400 - val_n_outputs0_loss: 0.1364 - val_n_outputs1_loss: 0.0037 Epoch 9/10 176/177 [============================&gt;.] - ETA: 0s - loss: 0.1295 - n_outputs0_loss: 0.1188 - n_outputs1_loss: 0.0107Epoch 1/10 44/177 [======&gt;.......................] - ETA: 2s - loss: 0.1272 - n_outputs0_loss: 0.1240 - n_outputs1_loss: 0.0032 Epoch 00009: val_loss improved from 0.14003 to 0.12723, saving model to /content/mycar/models/mypilot.h5 177/177 [==============================] - 10s 54ms/step - loss: 0.1295 - n_outputs0_loss: 0.1188 - n_outputs1_loss: 0.0107 - val_loss: 0.1272 - val_n_outputs0_loss: 0.1240 - val_n_outputs1_loss: 0.0032 Epoch 10/10 175/177 [============================&gt;.] - ETA: 0s - loss: 0.1227 - n_outputs0_loss: 0.1121 - n_outputs1_loss: 0.0106Epoch 1/10 44/177 [======&gt;.......................] - ETA: 2s - loss: 0.1303 - n_outputs0_loss: 0.1281 - n_outputs1_loss: 0.0022 Epoch 00010: val_loss did not improve from 0.12723 177/177 [==============================] - 9s 52ms/step - loss: 0.1227 - n_outputs0_loss: 0.1122 - n_outputs1_loss: 0.0105 - val_loss: 0.1303 - val_n_outputs0_loss: 0.1281 - val_n_outputs1_loss: 0.0022 Training completed in 0:01:43. -- Best Eval Loss :0.127232 &lt;Figure size 640x480 with 1 Axes&gt; . Step 4 opt B: Train RNN model . The RNN model combines several images to calculate steering and throttle. Use the manage.py script to start training . !python /content/mycar/manage.py train --type rnn --model /content/mycar/models/mypilot.h5 --aug . using donkey v3.1.1 ... loading config file: /content/mycar/config.py loading personal config over-rides config loaded sequence of images training &#34;get_model_by_type&#34; model Type is: rnn WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating: If using Keras pass *_constraint arguments to layers. Tub: /content/mycar/data/20-data has 0 records Tub: /content/mycar/data/tub_36_19-04-13 has 9136 records collating records collating sequences collated 9116 sequences of length 6 train: 7293, validation: 1823 steps_per_epoch 113 Epoch 1/100 WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version. Instructions for updating: Use tf.where in 2.0, which has the same broadcast rule as np.where 2020-03-05 12:53:28.840607: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1 2020-03-05 12:53:28.889468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-03-05 12:53:28.889998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285 pciBusID: 0000:00:04.0 2020-03-05 12:53:28.903378: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1 2020-03-05 12:53:29.098293: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10 2020-03-05 12:53:29.267466: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10 2020-03-05 12:53:29.284831: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10 2020-03-05 12:53:29.556031: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10 2020-03-05 12:53:29.578459: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10 2020-03-05 12:53:30.112438: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7 2020-03-05 12:53:30.112621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-03-05 12:53:30.113216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-03-05 12:53:30.113720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0 2020-03-05 12:53:30.158589: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz 2020-03-05 12:53:30.158902: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x22f7100 initialized for platform Host (this does not guarantee that XLA will be used). Devices: 2020-03-05 12:53:30.158939: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version 2020-03-05 12:53:30.307178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-03-05 12:53:30.308151: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x22f7d40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices: 2020-03-05 12:53:30.308188: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0 2020-03-05 12:53:30.309480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-03-05 12:53:30.310231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285 pciBusID: 0000:00:04.0 2020-03-05 12:53:30.310350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1 2020-03-05 12:53:30.310393: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10 2020-03-05 12:53:30.310417: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10 2020-03-05 12:53:30.310435: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10 2020-03-05 12:53:30.310455: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10 2020-03-05 12:53:30.310473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10 2020-03-05 12:53:30.310491: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7 2020-03-05 12:53:30.310584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-03-05 12:53:30.311479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-03-05 12:53:30.312233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0 2020-03-05 12:53:30.315503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1 2020-03-05 12:53:30.316930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix: 2020-03-05 12:53:30.316974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 2020-03-05 12:53:30.316988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N 2020-03-05 12:53:30.318133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-03-05 12:53:30.325962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-03-05 12:53:30.326736: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0. 2020-03-05 12:53:30.326791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -&gt; physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0) 2020-03-05 12:53:38.334163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10 2020-03-05 12:53:39.849168: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7 112/113 [============================&gt;.] - ETA: 0s - loss: 0.1116Epoch 1/100 28/113 [======&gt;.......................] - ETA: 11s - loss: 0.1060 Epoch 00001: val_loss improved from inf to 0.10599, saving model to /content/mycar/models/mypilot.h5 113/113 [==============================] - 47s 413ms/step - loss: 0.1116 - val_loss: 0.1060 Epoch 2/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0850Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0661 Epoch 00002: val_loss improved from 0.10599 to 0.06613, saving model to /content/mycar/models/mypilot.h5 113/113 [==============================] - 17s 152ms/step - loss: 0.0847 - val_loss: 0.0661 Epoch 3/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0571Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0523 Epoch 00003: val_loss improved from 0.06613 to 0.05228, saving model to /content/mycar/models/mypilot.h5 113/113 [==============================] - 17s 154ms/step - loss: 0.0573 - val_loss: 0.0523 Epoch 4/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0486Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0434 Epoch 00004: val_loss improved from 0.05228 to 0.04336, saving model to /content/mycar/models/mypilot.h5 113/113 [==============================] - 17s 152ms/step - loss: 0.0487 - val_loss: 0.0434 Epoch 5/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0442Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0423 Epoch 00005: val_loss improved from 0.04336 to 0.04234, saving model to /content/mycar/models/mypilot.h5 113/113 [==============================] - 17s 152ms/step - loss: 0.0443 - val_loss: 0.0423 Epoch 6/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0403Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0346 Epoch 00006: val_loss improved from 0.04234 to 0.03459, saving model to /content/mycar/models/mypilot.h5 113/113 [==============================] - 17s 152ms/step - loss: 0.0403 - val_loss: 0.0346 Epoch 7/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0385Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0391 Epoch 00007: val_loss did not improve from 0.03459 113/113 [==============================] - 17s 151ms/step - loss: 0.0386 - val_loss: 0.0391 Epoch 8/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0342Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0298 Epoch 00008: val_loss improved from 0.03459 to 0.02981, saving model to /content/mycar/models/mypilot.h5 113/113 [==============================] - 17s 152ms/step - loss: 0.0341 - val_loss: 0.0298 Epoch 9/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0332Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0281 Epoch 00009: val_loss improved from 0.02981 to 0.02813, saving model to /content/mycar/models/mypilot.h5 113/113 [==============================] - 17s 152ms/step - loss: 0.0332 - val_loss: 0.0281 Epoch 10/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0285Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0256 Epoch 00010: val_loss improved from 0.02813 to 0.02561, saving model to /content/mycar/models/mypilot.h5 113/113 [==============================] - 17s 152ms/step - loss: 0.0286 - val_loss: 0.0256 Epoch 11/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0277Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0226 Epoch 00011: val_loss improved from 0.02561 to 0.02260, saving model to /content/mycar/models/mypilot.h5 113/113 [==============================] - 17s 152ms/step - loss: 0.0277 - val_loss: 0.0226 Epoch 12/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0249Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0226 Epoch 00012: val_loss improved from 0.02260 to 0.02256, saving model to /content/mycar/models/mypilot.h5 113/113 [==============================] - 17s 153ms/step - loss: 0.0249 - val_loss: 0.0226 Epoch 13/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0239Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0232 Epoch 00013: val_loss did not improve from 0.02256 113/113 [==============================] - 17s 151ms/step - loss: 0.0239 - val_loss: 0.0232 Epoch 14/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0222Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0203 Epoch 00014: val_loss improved from 0.02256 to 0.02034, saving model to /content/mycar/models/mypilot.h5 113/113 [==============================] - 17s 152ms/step - loss: 0.0221 - val_loss: 0.0203 Epoch 15/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0213Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0200 Epoch 00015: val_loss improved from 0.02034 to 0.01998, saving model to /content/mycar/models/mypilot.h5 113/113 [==============================] - 17s 152ms/step - loss: 0.0213 - val_loss: 0.0200 Epoch 16/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0208Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0190 Epoch 00016: val_loss improved from 0.01998 to 0.01904, saving model to /content/mycar/models/mypilot.h5 113/113 [==============================] - 17s 153ms/step - loss: 0.0208 - val_loss: 0.0190 Epoch 17/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0203Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0179 Epoch 00017: val_loss improved from 0.01904 to 0.01790, saving model to /content/mycar/models/mypilot.h5 113/113 [==============================] - 17s 153ms/step - loss: 0.0203 - val_loss: 0.0179 Epoch 18/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0185Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0183 Epoch 00018: val_loss did not improve from 0.01790 113/113 [==============================] - 17s 150ms/step - loss: 0.0185 - val_loss: 0.0183 Epoch 19/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0181Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0190 Epoch 00019: val_loss did not improve from 0.01790 113/113 [==============================] - 17s 151ms/step - loss: 0.0181 - val_loss: 0.0190 Epoch 20/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0178Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0167 Epoch 00020: val_loss improved from 0.01790 to 0.01673, saving model to /content/mycar/models/mypilot.h5 113/113 [==============================] - 17s 152ms/step - loss: 0.0178 - val_loss: 0.0167 Epoch 21/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0168Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0176 Epoch 00021: val_loss did not improve from 0.01673 113/113 [==============================] - 17s 150ms/step - loss: 0.0168 - val_loss: 0.0176 Epoch 22/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0166Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0178 Epoch 00022: val_loss did not improve from 0.01673 113/113 [==============================] - 17s 150ms/step - loss: 0.0166 - val_loss: 0.0178 Epoch 23/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0156Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0166 Epoch 00023: val_loss improved from 0.01673 to 0.01663, saving model to /content/mycar/models/mypilot.h5 113/113 [==============================] - 17s 152ms/step - loss: 0.0156 - val_loss: 0.0166 Epoch 24/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0155Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0153 Epoch 00024: val_loss improved from 0.01663 to 0.01530, saving model to /content/mycar/models/mypilot.h5 113/113 [==============================] - 17s 153ms/step - loss: 0.0155 - val_loss: 0.0153 Epoch 25/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0146Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0161 Epoch 00025: val_loss did not improve from 0.01530 113/113 [==============================] - 17s 151ms/step - loss: 0.0147 - val_loss: 0.0161 Epoch 26/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0153Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0166 Epoch 00026: val_loss did not improve from 0.01530 113/113 [==============================] - 17s 152ms/step - loss: 0.0153 - val_loss: 0.0166 Epoch 27/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0149Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0153 Epoch 00027: val_loss did not improve from 0.01530 113/113 [==============================] - 17s 150ms/step - loss: 0.0148 - val_loss: 0.0153 Epoch 28/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0141Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0141 Epoch 00028: val_loss improved from 0.01530 to 0.01410, saving model to /content/mycar/models/mypilot.h5 113/113 [==============================] - 17s 152ms/step - loss: 0.0140 - val_loss: 0.0141 Epoch 29/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0135Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0148 Epoch 00029: val_loss did not improve from 0.01410 113/113 [==============================] - 17s 150ms/step - loss: 0.0136 - val_loss: 0.0148 Epoch 30/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0134Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0146 Epoch 00030: val_loss did not improve from 0.01410 113/113 [==============================] - 17s 151ms/step - loss: 0.0134 - val_loss: 0.0146 Epoch 31/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0139Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0136 Epoch 00031: val_loss improved from 0.01410 to 0.01358, saving model to /content/mycar/models/mypilot.h5 113/113 [==============================] - 17s 153ms/step - loss: 0.0139 - val_loss: 0.0136 Epoch 32/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0134Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0130 Epoch 00032: val_loss improved from 0.01358 to 0.01305, saving model to /content/mycar/models/mypilot.h5 113/113 [==============================] - 17s 152ms/step - loss: 0.0135 - val_loss: 0.0130 Epoch 33/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0127Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0140 Epoch 00033: val_loss did not improve from 0.01305 113/113 [==============================] - 17s 151ms/step - loss: 0.0127 - val_loss: 0.0140 Epoch 34/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0125Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0146 Epoch 00034: val_loss did not improve from 0.01305 113/113 [==============================] - 17s 151ms/step - loss: 0.0125 - val_loss: 0.0146 Epoch 35/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0123Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0135 Epoch 00035: val_loss did not improve from 0.01305 113/113 [==============================] - 17s 151ms/step - loss: 0.0123 - val_loss: 0.0135 Epoch 36/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0118Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0141 Epoch 00036: val_loss did not improve from 0.01305 113/113 [==============================] - 17s 151ms/step - loss: 0.0118 - val_loss: 0.0141 Epoch 37/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0117Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0121 Epoch 00037: val_loss improved from 0.01305 to 0.01206, saving model to /content/mycar/models/mypilot.h5 113/113 [==============================] - 17s 153ms/step - loss: 0.0118 - val_loss: 0.0121 Epoch 38/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0118Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0127 Epoch 00038: val_loss did not improve from 0.01206 113/113 [==============================] - 17s 151ms/step - loss: 0.0118 - val_loss: 0.0127 Epoch 39/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0116Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0131 Epoch 00039: val_loss did not improve from 0.01206 113/113 [==============================] - 17s 150ms/step - loss: 0.0116 - val_loss: 0.0131 Epoch 40/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0112Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0122 Epoch 00040: val_loss did not improve from 0.01206 113/113 [==============================] - 17s 151ms/step - loss: 0.0112 - val_loss: 0.0122 Epoch 41/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0112Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0123 Epoch 00041: val_loss did not improve from 0.01206 113/113 [==============================] - 17s 151ms/step - loss: 0.0112 - val_loss: 0.0123 Epoch 42/100 112/113 [============================&gt;.] - ETA: 0s - loss: 0.0111Epoch 1/100 28/113 [======&gt;.......................] - ETA: 8s - loss: 0.0129 Epoch 00042: val_loss did not improve from 0.01206 113/113 [==============================] - 17s 151ms/step - loss: 0.0110 - val_loss: 0.0129 Epoch 00042: early stopping Training completed in 0:12:29. -- Best Eval Loss :0.012056 &lt;Figure size 640x480 with 1 Axes&gt; . Step 5: Check model and transfer data . To check the quality of the model we look at the loss curve and see how well commanded and predicted steering and throttle values match. We transfer the data to the car and show how to start the self driving car. . Plot loss curve of model . The curve should show smaller loss vs epochs and the train and validation loss should not differ too much. . Tip: If train loss is much smaller than validation loss your model might be overfitting. . %cd /content/mycar/models file = glob.glob(&quot;*.png&quot;) Image(file[0]) . /content/mycar/models . Plot commands and predictions . You can use . donkey tubplot &lt;tub_path&gt; [--model=&lt;model_path&gt;] . to plot the commands and predictions of steering and throttle . %cd /content/mycar !donkey tubplot --tub=data/ --tub=data/tub_36_19-04-13 --model=models/mypilot.h5 file = glob.glob(&quot;/content/mycar/models/mypilot.h5_pred.png&quot;) Image(file[0]) . /content/mycar using donkey v3.1.1 ... loading config file: ./config.py loading personal config over-rides config loaded &#34;get_model_by_type&#34; model Type is: linear WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating: If using Keras pass *_constraint arguments to layers. WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version. Instructions for updating: Call initializer instance with the dtype argument instead of passing it to the constructor WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version. Instructions for updating: Call initializer instance with the dtype argument instead of passing it to the constructor WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version. Instructions for updating: Call initializer instance with the dtype argument instead of passing it to the constructor 2020-03-05 13:26:25.992189: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1 2020-03-05 13:26:26.004475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-03-05 13:26:26.005067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285 pciBusID: 0000:00:04.0 2020-03-05 13:26:26.005381: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1 2020-03-05 13:26:26.006910: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10 2020-03-05 13:26:26.008815: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10 2020-03-05 13:26:26.009106: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10 2020-03-05 13:26:26.010865: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10 2020-03-05 13:26:26.011718: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10 2020-03-05 13:26:26.015074: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7 2020-03-05 13:26:26.015184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-03-05 13:26:26.015762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-03-05 13:26:26.016258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0 2020-03-05 13:26:26.021029: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz 2020-03-05 13:26:26.021207: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x71f6fc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices: 2020-03-05 13:26:26.021232: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version 2020-03-05 13:26:26.108133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-03-05 13:26:26.108868: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x71f7180 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices: 2020-03-05 13:26:26.108900: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0 2020-03-05 13:26:26.109070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-03-05 13:26:26.109597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285 pciBusID: 0000:00:04.0 2020-03-05 13:26:26.109657: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1 2020-03-05 13:26:26.109672: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10 2020-03-05 13:26:26.109685: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10 2020-03-05 13:26:26.109698: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10 2020-03-05 13:26:26.109712: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10 2020-03-05 13:26:26.109725: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10 2020-03-05 13:26:26.109738: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7 2020-03-05 13:26:26.109807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-03-05 13:26:26.110361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-03-05 13:26:26.110839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0 2020-03-05 13:26:26.110891: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1 2020-03-05 13:26:26.111899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix: 2020-03-05 13:26:26.111925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 2020-03-05 13:26:26.111935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N 2020-03-05 13:26:26.112039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-03-05 13:26:26.112594: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero 2020-03-05 13:26:26.113075: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0. 2020-03-05 13:26:26.113110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -&gt; physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0) WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually. processing 1000 records: 2020-03-05 13:26:26.925787: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10 2020-03-05 13:26:27.167339: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7 &lt;Figure size 640x480 with 2 Axes&gt; . Copy the trained model back to Donkey Car (Pi) . Once the training is complete on Colab, download . mypilot.h5 file from /content/mycar/models/ | myconfig.py file from /content/mycar/ | . . files.download(&#39;./mypilot.h5&#39;) %cd /content/mycar files.download(&#39;myconfig.py&#39;) . /content/mycar . Alternatively, you can copy the model back to Google Drive too . !cp /content/mycar/models/mypilot.h5 /content/drive/My Drive/myCar/mypilot.h5 . Copy the file from your PC or Mac to the Raspberry Pi using Filezilla or scp command. . sftp pi@raspberry.local cd mycar/models put mypilot.h5 . Start Autopilot on Pi . cd ~/mycar python manage.py drive --model models/mypilot.h5 --js . Step 6: Bonus - Salient Object Visualization . The salient visualization gives an indication which parts of the image caused the highest activations in the model. Its a good method to understand what triggers the steering and indentify problems . reflections | distractions off the track . Note: It seems like the salient mode doesn&#8217;t work for RNN networks | . # !pip install git+https://github.com/autorope/keras-vis.git !pip uninstall keras-vis !pip install git+https://github.com/sctse999/keras-vis . Uninstalling keras-vis-0.4.1: Would remove: /usr/local/lib/python3.6/dist-packages/docs/* /usr/local/lib/python3.6/dist-packages/keras_vis-0.4.1.dist-info/* /usr/local/lib/python3.6/dist-packages/vis/* Would not remove (might be manually added): /usr/local/lib/python3.6/dist-packages/docs/autogen.py /usr/local/lib/python3.6/dist-packages/docs/structure.py Proceed (y/n)? y Successfully uninstalled keras-vis-0.4.1 Collecting git+https://github.com/sctse999/keras-vis Cloning https://github.com/sctse999/keras-vis to /tmp/pip-req-build-fppmjn_o Running command git clone -q https://github.com/sctse999/keras-vis /tmp/pip-req-build-fppmjn_o Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from keras-vis==0.5.0) (1.12.0) Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from keras-vis==0.5.0) (0.16.2) Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from keras-vis==0.5.0) (3.1.3) Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vis==0.5.0) (2.8.0) Requirement already satisfied: networkx&gt;=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image-&gt;keras-vis==0.5.0) (2.4) Requirement already satisfied: pillow&gt;=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image-&gt;keras-vis==0.5.0) (6.2.2) Requirement already satisfied: imageio&gt;=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image-&gt;keras-vis==0.5.0) (2.4.1) Requirement already satisfied: PyWavelets&gt;=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image-&gt;keras-vis==0.5.0) (1.1.1) Requirement already satisfied: scipy&gt;=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image-&gt;keras-vis==0.5.0) (1.4.1) Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib-&gt;keras-vis==0.5.0) (0.10.0) Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib-&gt;keras-vis==0.5.0) (2.4.6) Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib-&gt;keras-vis==0.5.0) (1.1.0) Requirement already satisfied: numpy&gt;=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib-&gt;keras-vis==0.5.0) (1.17.5) Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib-&gt;keras-vis==0.5.0) (2.6.1) Requirement already satisfied: decorator&gt;=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx&gt;=2.0-&gt;scikit-image-&gt;keras-vis==0.5.0) (4.4.1) Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver&gt;=1.0.1-&gt;matplotlib-&gt;keras-vis==0.5.0) (45.1.0) Building wheels for collected packages: keras-vis Building wheel for keras-vis (setup.py) ... done Created wheel for keras-vis: filename=keras_vis-0.5.0-py2.py3-none-any.whl size=38989 sha256=3425b80d2a4c02e113e49cc0eac6273520739475597a75c838d65a26dba7950b Stored in directory: /tmp/pip-ephem-wheel-cache-5ih_t8yg/wheels/29/87/8e/abd2257f08391eabe7552711aecf08cbb50f79877210b21be0 Successfully built keras-vis Installing collected packages: keras-vis Successfully installed keras-vis-0.5.0 . %cd /content/mycar !donkey makemovie --tub data/{tub_name} --model models/mypilot.h5 --type linear --salient . Download the movie to local machine . %cd /content/mycar !ls -ahl files.download(&#39;tub_movie.mp4&#39;) . /content/mycar total 89M drwxr-xr-x 6 root root 4.0K Mar 2 11:48 . drwxr-xr-x 1 root root 4.0K Mar 2 10:52 .. -rw-r--r-- 1 root root 13K Mar 2 10:51 config.py drwxr-xr-x 3 root root 4.0K Mar 2 10:52 data drwxr-xr-x 2 root root 4.0K Mar 2 10:51 logs -rw-r--r-- 1 root root 23K Mar 2 10:51 manage.py drwxr-xr-x 2 root root 4.0K Mar 2 11:35 models -rw-r--r-- 1 root root 14K Mar 2 10:52 myconfig.py -rw-r--r-- 1 root root 1.8M Mar 2 11:46 mypilot.h5 drwxr-xr-x 2 root root 4.0K Mar 2 10:54 __pycache__ -rw-r--r-- 1 root root 39K Mar 2 10:51 train.py -rw-r--r-- 1 root root 39M Mar 2 11:50 tub_movie.mp4 -rw- 1 root root 49M Mar 2 11:46 tubVaihingenIIICleaned200126.tar.gz . Or download the file to Google Drive . !cp /content/mycar/tub_movie.mp4 /content/drive/My Drive/myCar/tub_movie.mp4 .",
            "url": "https://uwesterr.github.io/MlFastAiBlog/donkeycar/colab/2020/03/01/TrainDonkeyCar.html",
            "relUrl": "/donkeycar/colab/2020/03/01/TrainDonkeyCar.html",
            "date": " • Mar 1, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Colabguide",
            "content": "Working with fastpages, GitHub and Colab . . The idea is to work with Jupyter Notebook in Colab, the notebook is part of a Fastpages blog and should be edited either in Colab or VS Code . write a Blog in Fastpages | format of Blog is Jupyter Notebook | run the Notebook in Colab | also edit in VS Code is necessary use Git to synchronize GitHub repo with VS Code local copy | . | . Write a blog with Fastpages . A detailed instruction on how to write Fastpage blogs is given at . for juypter notebooks | for markdown | . Working with notebook in Colab . Once the blog is opened there are buttons . View on GitHub The Jupyter Notbeook file is opened in the GitHub environment | Open in Colab The Jupyter Notbeook file is opened in the Colab environment 1 | . In the Colab environment the file can be run with GPU support. An intro to Colab is given here . To save the changes chose under “File” the option “Save a copy in GitHub” as shown below . . . . Colab will open a dialog as shown below It might be that it asks for your GitHub credentials before opening the dialog . . . . Working with VS Code . To work with the Fastpages blog clone the repository as described here . It is then easy to synchronize with GitHub, note, don’t forget to pull the repo once you saved a notebook version from Colab to GitHub. . Avoid conflicting versions . If you do the following . Change file in Colab | Save to GitHub | Change same file in VS | Try to push | . You will have *conflicts in the file** and need command line magic to solve the issue. I ended up setting the whole blog up from scratch. . Better: use Git: Snyc which does a Git: Pull first and then a Git: Push . Anybody can open a copy of any github-hosted notebook within Colab just add for markup [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb) or for html &lt;a href=&quot;https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb&quot;&gt; &lt;img src=&quot;https://colab.research.google.com/assets/colab-badge. svg&quot; alt=&quot;Open In Colab&quot;/&gt; &lt;/a&gt; &#8617; . |",
            "url": "https://uwesterr.github.io/MlFastAiBlog/fastpages/github/jupyter%20notebook/vs%20code/colab/2020/03/01/ColabGuide.html",
            "relUrl": "/fastpages/github/jupyter%20notebook/vs%20code/colab/2020/03/01/ColabGuide.html",
            "date": " • Mar 1, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . Front Matter is a markdown cell at the beginning of your notebook that allows you to inject metadata into your notebook. For example: . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks just like you can with markdown. . For example, here is a footnote 1. . . This is the footnote.&#8617; . |",
            "url": "https://uwesterr.github.io/MlFastAiBlog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Test Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://uwesterr.github.io/MlFastAiBlog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Interested in machine learning since 2014, using it to improve laser communication in space and spreading the idea by teaching at: . University of applied science Esslingen | VHS Esslingen | .",
          "url": "https://uwesterr.github.io/MlFastAiBlog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}